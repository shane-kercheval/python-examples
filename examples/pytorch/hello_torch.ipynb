{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conda environment used:\n",
    "\n",
    "`conda install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia`\n",
    "\n",
    "https://pytorch.org/get-started/locally/#linux-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "assert torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NVIDIA GeForce GTX 1080 Ti'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.get_device_name(torch.cuda.current_device())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0034, 0.2483, 0.7439],\n",
      "        [0.4013, 0.8217, 0.9261],\n",
      "        [0.1986, 0.5877, 0.4049],\n",
      "        [0.4868, 0.2526, 0.3390],\n",
      "        [0.3640, 0.1574, 0.0906]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n",
      "tensor([4, 5, 6], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "a = [1, 2, 3]\n",
    "b = np.array([4, 5, 6], dtype=np.int32)\n",
    "t_a = torch.tensor(a)\n",
    "t_b = torch.from_numpy(b)\n",
    "\n",
    "print(t_a)\n",
    "print(t_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1)\n",
    "t1 = 2 * torch.rand(5, 2) - 1\n",
    "t2 = torch.normal(mean=0, std=1, size=(5, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5153, -0.4414],\n",
      "        [-0.1939,  0.4694],\n",
      "        [-0.9414,  0.5997],\n",
      "        [-0.2057,  0.5087],\n",
      "        [ 0.1390, -0.1224]])\n",
      "tensor([[ 0.8590,  0.7056],\n",
      "        [-0.3406, -1.2720],\n",
      "        [-1.1948,  0.0250],\n",
      "        [-0.7627,  1.3969],\n",
      "        [-0.3245,  0.2879]])\n"
     ]
    }
   ],
   "source": [
    "print(t1)\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4426, -0.3114],\n",
       "        [ 0.0660, -0.5970],\n",
       "        [ 1.1249,  0.0150],\n",
       "        [ 0.1569,  0.7107],\n",
       "        [-0.0451, -0.0352]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = torch.multiply(t1, t2)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.4426, -0.3114],\n",
       "        [ 0.0660, -0.5970],\n",
       "        [ 1.1249,  0.0150],\n",
       "        [ 0.1569,  0.7107],\n",
       "        [-0.0451, -0.0352]], device='cuda:0')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_cuda = torch.device('cuda')\n",
    "results = torch.multiply(t1.to(device=device_cuda), t2.to(device=device_cuda))\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** CPU Speed **\n",
      "15.975645542144775\n",
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "matrix_size = 32*512\n",
    "\n",
    "x = torch.randn(matrix_size, matrix_size)\n",
    "y = torch.randn(matrix_size, matrix_size)\n",
    "\n",
    "print(\"** CPU Speed **\")\n",
    "start = time.time()\n",
    "result = torch.matmul(x, y)\n",
    "end = time.time()\n",
    "\n",
    "print(end - start)\n",
    "print(f\"device: {result.device}\")\n",
    "\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "** GPU Speed **\n",
      "0.0003991127014160156\n",
      "device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "x_gpu = x.to(torch.device('cuda'))\n",
    "y_gpu = y.to(torch.device('cuda'))\n",
    "\n",
    "print(\"** GPU Speed **\")\n",
    "start = time.time()\n",
    "gpu_result = torch.matmul(x_gpu, y_gpu)\n",
    "end = time.time()\n",
    "\n",
    "print(end - start)\n",
    "print(f\"device: {gpu_result.device}\")\n",
    "\n",
    "torch.cuda.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('pytorch_test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d8a0bdc463d56ed244abe5906a69519f028980e0802f09d52631d7fb963bd898"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
