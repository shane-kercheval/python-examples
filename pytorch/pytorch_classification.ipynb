{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "\n",
    "image_path = './'\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "mnist_train_dataset = torchvision.datasets.MNIST(\n",
    "    root=image_path, \n",
    "    train=True, \n",
    "    transform=transform, \n",
    "    download=True\n",
    ")\n",
    "mnist_test_dataset = torchvision.datasets.MNIST(\n",
    "    root=image_path,\n",
    "    train=False, \n",
    "    transform=transform, \n",
    "    download=False\n",
    ")\n",
    "\n",
    "batch_size = 64\n",
    "torch.manual_seed(1)\n",
    "train_dl = DataLoader(mnist_train_dataset, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_train_dataset[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Size: torch.Size([1, 28, 28])\n",
      "Input Size: 784\n",
      "Adding Linear Layer with 784 inputs and 32 outputs.\n",
      "Adding Linear Layer with 32 inputs and 16 outputs.\n",
      "Adding Output (Linear) Layer with 16 inputs and 10 outputs.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=784, out_features=32, bias=True)\n",
       "  (2): ReLU()\n",
       "  (3): Linear(in_features=32, out_features=16, bias=True)\n",
       "  (4): ReLU()\n",
       "  (5): Linear(in_features=16, out_features=10, bias=True)\n",
       "  (6): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_units = [32, 16]\n",
    "image_size = mnist_train_dataset[0][0].shape\n",
    "print(f\"Image Size: {image_size}\")\n",
    "input_size = image_size[0] * image_size[1] * image_size[2]\n",
    "print(f\"Input Size: {input_size}\")\n",
    "\n",
    "all_layers = [nn.Flatten()]\n",
    "for hidden_unit in hidden_units:\n",
    "    print(f\"Adding Linear Layer with {input_size} inputs and {hidden_unit} outputs.\")\n",
    "    layer = nn.Linear(input_size, hidden_unit)\n",
    "    all_layers.append(layer)\n",
    "    all_layers.append(nn.ReLU())\n",
    "    input_size = hidden_unit\n",
    "\n",
    "print(f\"Adding Output (Linear) Layer with {hidden_units[-1]} inputs and {10} outputs.\")\n",
    "all_layers.append(nn.Linear(hidden_units[-1], 10))\n",
    "all_layers.append(nn.Softmax(dim=1))\n",
    "model = nn.Sequential(*all_layers)\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0  Accuracy 0.8253\n",
      "Epoch 1  Accuracy 0.9164\n",
      "Epoch 2  Accuracy 0.9284\n",
      "Epoch 3  Accuracy 0.9367\n",
      "Epoch 4  Accuracy 0.9422\n",
      "Epoch 5  Accuracy 0.9461\n",
      "Epoch 6  Accuracy 0.9510\n",
      "Epoch 7  Accuracy 0.9534\n",
      "Epoch 8  Accuracy 0.9567\n",
      "Epoch 9  Accuracy 0.9588\n",
      "Epoch 10  Accuracy 0.9608\n",
      "Epoch 11  Accuracy 0.9624\n",
      "Epoch 12  Accuracy 0.9637\n",
      "Epoch 13  Accuracy 0.9656\n",
      "Epoch 14  Accuracy 0.9662\n",
      "Epoch 15  Accuracy 0.9679\n",
      "Epoch 16  Accuracy 0.9680\n",
      "Epoch 17  Accuracy 0.9693\n",
      "Epoch 18  Accuracy 0.9702\n",
      "Epoch 19  Accuracy 0.9708\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "torch.manual_seed(1)\n",
    "num_epochs = 20\n",
    "for epoch in range(num_epochs):\n",
    "    accuracy_hist_train = 0\n",
    "    for x_batch, y_batch in train_dl:\n",
    "        pred = model(x_batch)\n",
    "        loss = loss_fn(pred, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        is_correct = (torch.argmax(pred, dim=1) == y_batch).float()\n",
    "        accuracy_hist_train += is_correct.sum()\n",
    "    accuracy_hist_train /= len(train_dl.dataset)\n",
    "    print(f'Epoch {epoch}  Accuracy {accuracy_hist_train:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9583\n"
     ]
    }
   ],
   "source": [
    "pred = model(mnist_test_dataset.data / 255.)\n",
    "is_correct = (torch.argmax(pred, dim=1) == mnist_test_dataset.targets).float()\n",
    "print(f'Test accuracy: {is_correct.mean():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.8743e-24, 1.9608e-28, 9.4058e-19, 1.0751e-12, 5.0737e-25, 1.7463e-23,\n",
       "        0.0000e+00, 1.0000e+00, 9.5882e-19, 4.4985e-20],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sum(pred[0]) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('pytorch_test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1b7f59ecf0b0c490ceca568dedb7540b6ac55c9a93fe41ae65e3445c4b6da78e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
