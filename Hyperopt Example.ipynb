{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5355fe9",
   "metadata": {},
   "source": [
    "```\n",
    "pip install hyperopt==0.2.5\n",
    "```\n",
    "\n",
    "https://github.com/maxpumperla/hyperas/issues/284"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0372b3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install git+https://github.com/hyperopt/hyperopt-sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c830ec15",
   "metadata": {},
   "source": [
    "Code from: https://github.com/hyperopt/hyperopt-sklearn\n",
    "\n",
    "`pip install git+https://github.com/hyperopt/hyperopt-sklearn`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0536bcfa",
   "metadata": {},
   "source": [
    "> For a simple generic search space across many classifiers, use `any_classifier`. If your data is in a sparse matrix format, use `any_sparse_classifier`.\n",
    "> \n",
    "> For a simple generic search space across many regressors, use `any_regressor`. If your data is in a sparse matrix format, use `any_sparse_regressor`.\n",
    ">\n",
    "> For a simple generic search space across many preprocessing algorithms, use `any_preprocessing`. If you are working with raw text data, use `any_text_preprocessing`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205a7019",
   "metadata": {},
   "source": [
    "We might have an issue using `AUC`\n",
    "\n",
    "https://github.com/hyperopt/hyperopt-sklearn/issues/141"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6655261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.09s/trial, best loss: 0.04166666666666663]\n",
      " 50%|█████     | 1/2 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 2/2 [00:00<00:00,  1.36trial/s, best loss: 0.04166666666666663]\n",
      " 67%|██████▋   | 2/3 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 3/3 [00:01<00:00,  1.04s/trial, best loss: 0.04166666666666663]\n",
      " 75%|███████▌  | 3/4 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 4/4 [00:01<00:00,  1.43s/trial, best loss: 0.04166666666666663]\n",
      " 80%|████████  | 4/5 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 5/5 [00:00<00:00,  1.36trial/s, best loss: 0.04166666666666663]\n",
      " 83%|████████▎ | 5/6 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 6/6 [00:01<00:00,  1.03s/trial, best loss: 0.04166666666666663]\n",
      " 86%|████████▌ | 6/7 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shanekercheval/opt/anaconda3/envs/python-examples/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "[15:30:55] WARNING: /private/var/folders/7x/wc3jx_91337bggbzk01kpvs40000gn/T/pip-install-9asvcns4/xgboost_6cd18ae4d2a4469e8f54a1f945448b8a/build/temp.macosx-10.9-x86_64-3.9/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:30:55] WARNING: /private/var/folders/7x/wc3jx_91337bggbzk01kpvs40000gn/T/pip-install-9asvcns4/xgboost_6cd18ae4d2a4469e8f54a1f945448b8a/build/temp.macosx-10.9-x86_64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 7/7 [00:01<00:00,  1.17s/trial, best loss: 0.04166666666666663]\n",
      " 88%|████████▊ | 7/8 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 8/8 [00:00<00:00,  1.31trial/s, best loss: 0.04166666666666663]\n",
      " 89%|████████▉ | 8/9 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 9/9 [00:00<00:00,  1.36trial/s, best loss: 0.04166666666666663]\n",
      " 90%|█████████ | 9/10 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 10/10 [00:00<00:00,  1.29trial/s, best loss: 0.04166666666666663]\n",
      " 91%|█████████ | 10/11 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 11/11 [00:00<00:00,  1.30trial/s, best loss: 0.04166666666666663]\n",
      " 92%|█████████▏| 11/12 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 12/12 [00:00<00:00,  1.28trial/s, best loss: 0.04166666666666663]\n",
      " 92%|█████████▏| 12/13 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shanekercheval/opt/anaconda3/envs/python-examples/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "[15:31:00] WARNING: /private/var/folders/7x/wc3jx_91337bggbzk01kpvs40000gn/T/pip-install-9asvcns4/xgboost_6cd18ae4d2a4469e8f54a1f945448b8a/build/temp.macosx-10.9-x86_64-3.9/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:31:00] WARNING: /private/var/folders/7x/wc3jx_91337bggbzk01kpvs40000gn/T/pip-install-9asvcns4/xgboost_6cd18ae4d2a4469e8f54a1f945448b8a/build/temp.macosx-10.9-x86_64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 13/13 [00:01<00:00,  1.05s/trial, best loss: 0.04166666666666663]\n",
      " 93%|█████████▎| 13/14 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 14/14 [00:01<00:00,  1.21s/trial, best loss: 0.04166666666666663]\n",
      " 93%|█████████▎| 14/15 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 15/15 [00:01<00:00,  1.18s/trial, best loss: 0.04166666666666663]\n",
      " 94%|█████████▍| 15/16 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 16/16 [00:00<00:00,  1.30trial/s, best loss: 0.04166666666666663]\n",
      " 94%|█████████▍| 16/17 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 17/17 [00:00<00:00,  1.19trial/s, best loss: 0.04166666666666663]\n",
      " 94%|█████████▍| 17/18 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 18/18 [00:00<00:00,  1.31trial/s, best loss: 0.04166666666666663]\n",
      " 95%|█████████▍| 18/19 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 19/19 [00:03<00:00,  3.14s/trial, best loss: 0.04166666666666663]\n",
      " 95%|█████████▌| 19/20 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 20/20 [00:00<00:00,  1.07trial/s, best loss: 0.04166666666666663]\n",
      " 95%|█████████▌| 20/21 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 21/21 [00:00<00:00,  1.25trial/s, best loss: 0.04166666666666663]\n",
      " 95%|█████████▌| 21/22 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 22/22 [00:00<00:00,  1.14trial/s, best loss: 0.04166666666666663]\n",
      " 96%|█████████▌| 22/23 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 23/23 [00:00<00:00,  1.15trial/s, best loss: 0.04166666666666663]\n",
      " 96%|█████████▌| 23/24 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 24/24 [00:00<00:00,  1.15trial/s, best loss: 0.04166666666666663]\n",
      " 96%|█████████▌| 24/25 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 25/25 [00:00<00:00,  1.20trial/s, best loss: 0.04166666666666663]\n",
      " 96%|█████████▌| 25/26 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 26/26 [00:01<00:00,  1.04s/trial, best loss: 0.04166666666666663]\n",
      " 96%|█████████▋| 26/27 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 27/27 [00:01<00:00,  1.45s/trial, best loss: 0.04166666666666663]\n",
      " 96%|█████████▋| 27/28 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 28/28 [00:01<00:00,  1.90s/trial, best loss: 0.04166666666666663]\n",
      " 97%|█████████▋| 28/29 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 29/29 [00:00<00:00,  1.23trial/s, best loss: 0.04166666666666663]\n",
      " 97%|█████████▋| 29/30 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 30/30 [00:00<00:00,  1.26trial/s, best loss: 0.04166666666666663]\n",
      " 97%|█████████▋| 30/31 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 31/31 [00:00<00:00,  1.22trial/s, best loss: 0.04166666666666663]\n",
      " 97%|█████████▋| 31/32 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 32/32 [00:00<00:00,  1.17trial/s, best loss: 0.04166666666666663]\n",
      " 97%|█████████▋| 32/33 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 33/33 [00:00<00:00,  1.19trial/s, best loss: 0.04166666666666663]\n",
      " 97%|█████████▋| 33/34 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shanekercheval/opt/anaconda3/envs/python-examples/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "[15:31:24] WARNING: /private/var/folders/7x/wc3jx_91337bggbzk01kpvs40000gn/T/pip-install-9asvcns4/xgboost_6cd18ae4d2a4469e8f54a1f945448b8a/build/temp.macosx-10.9-x86_64-3.9/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:31:24] WARNING: /private/var/folders/7x/wc3jx_91337bggbzk01kpvs40000gn/T/pip-install-9asvcns4/xgboost_6cd18ae4d2a4469e8f54a1f945448b8a/build/temp.macosx-10.9-x86_64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 34/34 [00:01<00:00,  1.89s/trial, best loss: 0.04166666666666663]\n",
      " 97%|█████████▋| 34/35 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 35/35 [00:01<00:00,  1.57s/trial, best loss: 0.04166666666666663]\n",
      " 97%|█████████▋| 35/36 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 36/36 [00:02<00:00,  2.31s/trial, best loss: 0.04166666666666663]\n",
      " 97%|█████████▋| 36/37 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shanekercheval/opt/anaconda3/envs/python-examples/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "[15:31:30] WARNING: /private/var/folders/7x/wc3jx_91337bggbzk01kpvs40000gn/T/pip-install-9asvcns4/xgboost_6cd18ae4d2a4469e8f54a1f945448b8a/build/temp.macosx-10.9-x86_64-3.9/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:31:30] WARNING: /private/var/folders/7x/wc3jx_91337bggbzk01kpvs40000gn/T/pip-install-9asvcns4/xgboost_6cd18ae4d2a4469e8f54a1f945448b8a/build/temp.macosx-10.9-x86_64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 37/37 [00:01<00:00,  1.82s/trial, best loss: 0.04166666666666663]\n",
      " 97%|█████████▋| 37/38 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 38/38 [00:00<00:00,  1.20trial/s, best loss: 0.04166666666666663]\n",
      " 97%|█████████▋| 38/39 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 39/39 [00:00<00:00,  1.23trial/s, best loss: 0.04166666666666663]\n",
      " 98%|█████████▊| 39/40 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shanekercheval/opt/anaconda3/envs/python-examples/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "[15:31:34] WARNING: /private/var/folders/7x/wc3jx_91337bggbzk01kpvs40000gn/T/pip-install-9asvcns4/xgboost_6cd18ae4d2a4469e8f54a1f945448b8a/build/temp.macosx-10.9-x86_64-3.9/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:31:34] WARNING: /private/var/folders/7x/wc3jx_91337bggbzk01kpvs40000gn/T/pip-install-9asvcns4/xgboost_6cd18ae4d2a4469e8f54a1f945448b8a/build/temp.macosx-10.9-x86_64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 40/40 [00:01<00:00,  1.79s/trial, best loss: 0.04166666666666663]\n",
      " 98%|█████████▊| 40/41 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shanekercheval/opt/anaconda3/envs/python-examples/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "[15:31:36] WARNING: /private/var/folders/7x/wc3jx_91337bggbzk01kpvs40000gn/T/pip-install-9asvcns4/xgboost_6cd18ae4d2a4469e8f54a1f945448b8a/build/temp.macosx-10.9-x86_64-3.9/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:31:36] WARNING: /private/var/folders/7x/wc3jx_91337bggbzk01kpvs40000gn/T/pip-install-9asvcns4/xgboost_6cd18ae4d2a4469e8f54a1f945448b8a/build/temp.macosx-10.9-x86_64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 41/41 [00:01<00:00,  1.48s/trial, best loss: 0.04166666666666663]\n",
      " 98%|█████████▊| 41/42 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "[15:31:37] WARNING: /private/var/folders/7x/wc3jx_91337bggbzk01kpvs40000gn/T/pip-install-9asvcns4/xgboost_6cd18ae4d2a4469e8f54a1f945448b8a/build/temp.macosx-10.9-x86_64-3.9/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:31:37] WARNING: /private/var/folders/7x/wc3jx_91337bggbzk01kpvs40000gn/T/pip-install-9asvcns4/xgboost_6cd18ae4d2a4469e8f54a1f945448b8a/build/temp.macosx-10.9-x86_64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 42/42 [00:00<00:00,  1.16trial/s, best loss: 0.04166666666666663]\n",
      " 98%|█████████▊| 42/43 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shanekercheval/opt/anaconda3/envs/python-examples/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 43/43 [00:00<00:00,  1.29trial/s, best loss: 0.04166666666666663]\n",
      " 98%|█████████▊| 43/44 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shanekercheval/opt/anaconda3/envs/python-examples/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:165: FutureWarning: The loss 'squared_loss' was deprecated in v1.0 and will be removed in version 1.2. Use `loss='squared_error'` which is equivalent.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 44/44 [00:00<00:00,  1.28trial/s, best loss: 0.04166666666666663]\n",
      " 98%|█████████▊| 44/45 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shanekercheval/opt/anaconda3/envs/python-examples/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "[15:31:40] WARNING: /private/var/folders/7x/wc3jx_91337bggbzk01kpvs40000gn/T/pip-install-9asvcns4/xgboost_6cd18ae4d2a4469e8f54a1f945448b8a/build/temp.macosx-10.9-x86_64-3.9/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:31:40] WARNING: /private/var/folders/7x/wc3jx_91337bggbzk01kpvs40000gn/T/pip-install-9asvcns4/xgboost_6cd18ae4d2a4469e8f54a1f945448b8a/build/temp.macosx-10.9-x86_64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 45/45 [00:01<00:00,  1.02s/trial, best loss: 0.04166666666666663]\n",
      " 98%|█████████▊| 45/46 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 46/46 [00:00<00:00,  1.22trial/s, best loss: 0.04166666666666663]\n",
      " 98%|█████████▊| 46/47 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 47/47 [00:00<00:00,  1.30trial/s, best loss: 0.04166666666666663]\n",
      " 98%|█████████▊| 47/48 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 48/48 [00:00<00:00,  1.29trial/s, best loss: 0.04166666666666663]\n",
      " 98%|█████████▊| 48/49 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 49/49 [00:00<00:00,  1.25trial/s, best loss: 0.04166666666666663]\n",
      " 98%|█████████▊| 49/50 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 50/50 [00:00<00:00,  1.23trial/s, best loss: 0.04166666666666663]\n",
      " 98%|█████████▊| 50/51 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 51/51 [00:00<00:00,  1.28trial/s, best loss: 0.04166666666666663]\n",
      " 98%|█████████▊| 51/52 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 52/52 [00:00<00:00,  1.26trial/s, best loss: 0.04166666666666663]\n",
      " 98%|█████████▊| 52/53 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 53/53 [00:00<00:00,  1.21trial/s, best loss: 0.04166666666666663]\n",
      " 98%|█████████▊| 53/54 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 54/54 [00:00<00:00,  1.13trial/s, best loss: 0.04166666666666663]\n",
      " 98%|█████████▊| 54/55 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 55/55 [00:00<00:00,  1.23trial/s, best loss: 0.04166666666666663]\n",
      " 98%|█████████▊| 55/56 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 56/56 [00:00<00:00,  1.12trial/s, best loss: 0.04166666666666663]\n",
      " 98%|█████████▊| 56/57 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 57/57 [00:00<00:00,  1.18trial/s, best loss: 0.04166666666666663]\n",
      " 98%|█████████▊| 57/58 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 58/58 [00:00<00:00,  1.14trial/s, best loss: 0.04166666666666663]\n",
      " 98%|█████████▊| 58/59 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 59/59 [00:01<00:00,  1.25s/trial, best loss: 0.04166666666666663]\n",
      " 98%|█████████▊| 59/60 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 60/60 [00:00<00:00,  1.22trial/s, best loss: 0.04166666666666663]\n",
      " 98%|█████████▊| 60/61 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 61/61 [00:00<00:00,  1.23trial/s, best loss: 0.04166666666666663]\n",
      " 98%|█████████▊| 61/62 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shanekercheval/opt/anaconda3/envs/python-examples/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "[15:31:55] WARNING: /private/var/folders/7x/wc3jx_91337bggbzk01kpvs40000gn/T/pip-install-9asvcns4/xgboost_6cd18ae4d2a4469e8f54a1f945448b8a/build/temp.macosx-10.9-x86_64-3.9/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:31:55] WARNING: /private/var/folders/7x/wc3jx_91337bggbzk01kpvs40000gn/T/pip-install-9asvcns4/xgboost_6cd18ae4d2a4469e8f54a1f945448b8a/build/temp.macosx-10.9-x86_64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 62/62 [00:01<00:00,  1.66s/trial, best loss: 0.04166666666666663]\n",
      " 98%|█████████▊| 62/63 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 63/63 [00:00<00:00,  1.24trial/s, best loss: 0.04166666666666663]\n",
      " 98%|█████████▊| 63/64 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 64/64 [00:02<00:00,  2.17s/trial, best loss: 0.04166666666666663]\n",
      " 98%|█████████▊| 64/65 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 65/65 [00:00<00:00,  1.20trial/s, best loss: 0.04166666666666663]\n",
      " 98%|█████████▊| 65/66 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "[15:32:01] WARNING: /private/var/folders/7x/wc3jx_91337bggbzk01kpvs40000gn/T/pip-install-9asvcns4/xgboost_6cd18ae4d2a4469e8f54a1f945448b8a/build/temp.macosx-10.9-x86_64-3.9/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:32:01] WARNING: /private/var/folders/7x/wc3jx_91337bggbzk01kpvs40000gn/T/pip-install-9asvcns4/xgboost_6cd18ae4d2a4469e8f54a1f945448b8a/build/temp.macosx-10.9-x86_64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 66/66 [00:00<00:00,  1.22trial/s, best loss: 0.04166666666666663]\n",
      " 99%|█████████▊| 66/67 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shanekercheval/opt/anaconda3/envs/python-examples/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "[15:32:02] WARNING: /private/var/folders/7x/wc3jx_91337bggbzk01kpvs40000gn/T/pip-install-9asvcns4/xgboost_6cd18ae4d2a4469e8f54a1f945448b8a/build/temp.macosx-10.9-x86_64-3.9/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:32:02] WARNING: /private/var/folders/7x/wc3jx_91337bggbzk01kpvs40000gn/T/pip-install-9asvcns4/xgboost_6cd18ae4d2a4469e8f54a1f945448b8a/build/temp.macosx-10.9-x86_64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 67/67 [00:00<00:00,  1.22trial/s, best loss: 0.04166666666666663]\n",
      " 99%|█████████▊| 67/68 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shanekercheval/opt/anaconda3/envs/python-examples/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 68/68 [00:00<00:00,  1.11trial/s, best loss: 0.04166666666666663]\n",
      " 99%|█████████▊| 68/69 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 69/69 [00:01<00:00,  1.34s/trial, best loss: 0.04166666666666663]\n",
      " 99%|█████████▊| 69/70 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 70/70 [00:00<00:00,  1.26trial/s, best loss: 0.04166666666666663]\n",
      " 99%|█████████▊| 70/71 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 71/71 [00:01<00:00,  1.03s/trial, best loss: 0.04166666666666663]\n",
      " 99%|█████████▊| 71/72 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 72/72 [00:01<00:00,  1.16s/trial, best loss: 0.04166666666666663]\n",
      " 99%|█████████▊| 72/73 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 73/73 [00:00<00:00,  1.24trial/s, best loss: 0.04166666666666663]\n",
      " 99%|█████████▊| 73/74 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 74/74 [00:00<00:00,  1.23trial/s, best loss: 0.04166666666666663]\n",
      " 99%|█████████▊| 74/75 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 75/75 [00:00<00:00,  1.22trial/s, best loss: 0.04166666666666663]\n",
      " 99%|█████████▊| 75/76 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 76/76 [00:00<00:00,  1.19trial/s, best loss: 0.04166666666666663]\n",
      " 99%|█████████▊| 76/77 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shanekercheval/opt/anaconda3/envs/python-examples/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "[15:32:12] WARNING: /private/var/folders/7x/wc3jx_91337bggbzk01kpvs40000gn/T/pip-install-9asvcns4/xgboost_6cd18ae4d2a4469e8f54a1f945448b8a/build/temp.macosx-10.9-x86_64-3.9/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:32:12] WARNING: /private/var/folders/7x/wc3jx_91337bggbzk01kpvs40000gn/T/pip-install-9asvcns4/xgboost_6cd18ae4d2a4469e8f54a1f945448b8a/build/temp.macosx-10.9-x86_64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 77/77 [00:01<00:00,  1.99s/trial, best loss: 0.04166666666666663]\n",
      " 99%|█████████▊| 77/78 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 78/78 [00:00<00:00,  1.18trial/s, best loss: 0.04166666666666663]\n",
      " 99%|█████████▊| 78/79 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shanekercheval/opt/anaconda3/envs/python-examples/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "[15:32:15] WARNING: /private/var/folders/7x/wc3jx_91337bggbzk01kpvs40000gn/T/pip-install-9asvcns4/xgboost_6cd18ae4d2a4469e8f54a1f945448b8a/build/temp.macosx-10.9-x86_64-3.9/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:32:15] WARNING: /private/var/folders/7x/wc3jx_91337bggbzk01kpvs40000gn/T/pip-install-9asvcns4/xgboost_6cd18ae4d2a4469e8f54a1f945448b8a/build/temp.macosx-10.9-x86_64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 79/79 [00:01<00:00,  1.71s/trial, best loss: 0.04166666666666663]\n",
      " 99%|█████████▉| 79/80 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 80/80 [00:00<00:00,  1.16trial/s, best loss: 0.04166666666666663]\n",
      " 99%|█████████▉| 80/81 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 81/81 [00:00<00:00,  1.25trial/s, best loss: 0.04166666666666663]\n",
      " 99%|█████████▉| 81/82 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 82/82 [00:00<00:00,  1.28trial/s, best loss: 0.04166666666666663]\n",
      " 99%|█████████▉| 82/83 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 83/83 [00:01<00:00,  1.48s/trial, best loss: 0.04166666666666663]\n",
      " 99%|█████████▉| 83/84 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 84/84 [00:00<00:00,  1.21trial/s, best loss: 0.04166666666666663]\n",
      " 99%|█████████▉| 84/85 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shanekercheval/opt/anaconda3/envs/python-examples/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "[15:32:21] WARNING: /private/var/folders/7x/wc3jx_91337bggbzk01kpvs40000gn/T/pip-install-9asvcns4/xgboost_6cd18ae4d2a4469e8f54a1f945448b8a/build/temp.macosx-10.9-x86_64-3.9/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:32:21] WARNING: /private/var/folders/7x/wc3jx_91337bggbzk01kpvs40000gn/T/pip-install-9asvcns4/xgboost_6cd18ae4d2a4469e8f54a1f945448b8a/build/temp.macosx-10.9-x86_64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 85/85 [00:01<00:00,  1.44s/trial, best loss: 0.04166666666666663]\n",
      " 99%|█████████▉| 85/86 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 86/86 [00:02<00:00,  2.60s/trial, best loss: 0.04166666666666663]\n",
      " 99%|█████████▉| 86/87 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 87/87 [00:01<00:00,  1.34s/trial, best loss: 0.04166666666666663]\n",
      " 99%|█████████▉| 87/88 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 88/88 [00:00<00:00,  1.05trial/s, best loss: 0.04166666666666663]\n",
      " 99%|█████████▉| 88/89 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 89/89 [00:02<00:00,  2.76s/trial, best loss: 0.04166666666666663]\n",
      " 99%|█████████▉| 89/90 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 90/90 [00:01<00:00,  1.75s/trial, best loss: 0.04166666666666663]\n",
      " 99%|█████████▉| 90/91 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 91/91 [00:00<00:00,  1.16trial/s, best loss: 0.04166666666666663]\n",
      " 99%|█████████▉| 91/92 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 92/92 [00:00<00:00,  1.26trial/s, best loss: 0.04166666666666663]\n",
      " 99%|█████████▉| 92/93 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shanekercheval/opt/anaconda3/envs/python-examples/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "[15:32:34] WARNING: /private/var/folders/7x/wc3jx_91337bggbzk01kpvs40000gn/T/pip-install-9asvcns4/xgboost_6cd18ae4d2a4469e8f54a1f945448b8a/build/temp.macosx-10.9-x86_64-3.9/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:32:34] WARNING: /private/var/folders/7x/wc3jx_91337bggbzk01kpvs40000gn/T/pip-install-9asvcns4/xgboost_6cd18ae4d2a4469e8f54a1f945448b8a/build/temp.macosx-10.9-x86_64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 93/93 [00:02<00:00,  2.66s/trial, best loss: 0.04166666666666663]\n",
      " 99%|█████████▉| 93/94 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 94/94 [00:00<00:00,  1.19trial/s, best loss: 0.04166666666666663]\n",
      " 99%|█████████▉| 94/95 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 95/95 [00:00<00:00,  1.21trial/s, best loss: 0.04166666666666663]\n",
      " 99%|█████████▉| 95/96 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 96/96 [00:00<00:00,  1.28trial/s, best loss: 0.04166666666666663]\n",
      " 99%|█████████▉| 96/97 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 97/97 [00:00<00:00,  1.27trial/s, best loss: 0.04166666666666663]\n",
      " 99%|█████████▉| 97/98 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shanekercheval/opt/anaconda3/envs/python-examples/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "[15:32:41] WARNING: /private/var/folders/7x/wc3jx_91337bggbzk01kpvs40000gn/T/pip-install-9asvcns4/xgboost_6cd18ae4d2a4469e8f54a1f945448b8a/build/temp.macosx-10.9-x86_64-3.9/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:32:41] WARNING: /private/var/folders/7x/wc3jx_91337bggbzk01kpvs40000gn/T/pip-install-9asvcns4/xgboost_6cd18ae4d2a4469e8f54a1f945448b8a/build/temp.macosx-10.9-x86_64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 98/98 [00:01<00:00,  1.58s/trial, best loss: 0.04166666666666663]\n",
      " 99%|█████████▉| 98/99 [00:00<?, ?trial/s, best loss=?]WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "100%|██████████| 99/99 [00:01<00:00,  1.48s/trial, best loss: 0.04166666666666663]\n",
      " 99%|█████████▉| 99/100 [00:00<?, ?trial/s, best loss=?]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shanekercheval/opt/anaconda3/envs/python-examples/lib/python3.9/site-packages/xgboost/sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: OMP_NUM_THREADS=None =>\n",
      "... If you are using openblas if you are using openblas set OMP_NUM_THREADS=1 or risk subprocess calls hanging indefinitely\n",
      "[15:32:44] WARNING: /private/var/folders/7x/wc3jx_91337bggbzk01kpvs40000gn/T/pip-install-9asvcns4/xgboost_6cd18ae4d2a4469e8f54a1f945448b8a/build/temp.macosx-10.9-x86_64-3.9/xgboost/src/learner.cc:576: \n",
      "Parameters: { \"scale_pos_weight\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[15:32:44] WARNING: /private/var/folders/7x/wc3jx_91337bggbzk01kpvs40000gn/T/pip-install-9asvcns4/xgboost_6cd18ae4d2a4469e8f54a1f945448b8a/build/temp.macosx-10.9-x86_64-3.9/xgboost/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "100%|██████████| 100/100 [00:01<00:00,  1.40s/trial, best loss: 0.04166666666666663]\n",
      "1.0\n",
      "{'learner': GradientBoostingClassifier(learning_rate=0.109075631387922, max_depth=2,\n",
      "                           n_estimators=12, random_state=0,\n",
      "                           subsample=0.895536992039051), 'preprocs': (Normalizer(),), 'ex_preprocs': ()}\n"
     ]
    }
   ],
   "source": [
    "from hpsklearn import HyperoptEstimator, any_classifier, any_preprocessing\n",
    "from sklearn.datasets import load_iris\n",
    "from hyperopt import tpe\n",
    "import numpy as np\n",
    "\n",
    "# Download the data and split into training and test sets\n",
    "\n",
    "iris = load_iris()\n",
    "\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "test_size = int(0.2 * len(y))\n",
    "np.random.seed(13)\n",
    "indices = np.random.permutation(len(X))\n",
    "X_train = X[indices[:-test_size]]\n",
    "y_train = y[indices[:-test_size]]\n",
    "X_test = X[indices[-test_size:]]\n",
    "y_test = y[indices[-test_size:]]\n",
    "\n",
    "# Instantiate a HyperoptEstimator with the search space and number of evaluations\n",
    "\n",
    "estim = HyperoptEstimator(classifier=any_classifier('my_clf'),\n",
    "                          preprocessing=any_preprocessing('my_pre'),\n",
    "                          algo=tpe.suggest,\n",
    "                          max_evals=100,\n",
    "                          trial_timeout=120)\n",
    "\n",
    "# Search the hyperparameter space based on the data\n",
    "\n",
    "estim.fit(X_train, y_train)\n",
    "\n",
    "# Show the results\n",
    "\n",
    "print(estim.score(X_test, y_test))\n",
    "# 1.0\n",
    "\n",
    "print(estim.best_model())\n",
    "# {'learner': ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
    "#           max_depth=3, max_features='log2', max_leaf_nodes=None,\n",
    "#           min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "#           min_samples_leaf=1, min_samples_split=2,\n",
    "#           min_weight_fraction_leaf=0.0, n_estimators=13, n_jobs=1,\n",
    "#           oob_score=False, random_state=1, verbose=False,\n",
    "#           warm_start=False), 'preprocs': (), 'ex_preprocs': ()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1d7d9d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(estim.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2cd8b6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learner': GradientBoostingClassifier(learning_rate=0.109075631387922, max_depth=2,\n",
      "                           n_estimators=12, random_state=0,\n",
      "                           subsample=0.895536992039051), 'preprocs': (Normalizer(),), 'ex_preprocs': ()}\n"
     ]
    }
   ],
   "source": [
    "print(estim.best_model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "808158f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.01889801025390625},\n",
       " {'loss': 0.75,\n",
       "  'loss_variance': 0.008152173913043478,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.007817983627319336},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.3144409656524658},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.6567502021789551},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.005827903747558594},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.3058300018310547},\n",
       " {'loss': 0.5833333333333333,\n",
       "  'loss_variance': 0.010567632850241548,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.4021179676055908},\n",
       " {'loss': 0.33333333333333337,\n",
       "  'loss_variance': 0.009661835748792272,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.027526140213012695},\n",
       " {'loss': 0.125,\n",
       "  'loss_variance': 0.004755434782608696,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.002707958221435547},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.008484125137329102},\n",
       " {'loss': 0.33333333333333337,\n",
       "  'loss_variance': 0.009661835748792272,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.0396571159362793},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.03863382339477539},\n",
       " {'loss': 0.5833333333333333,\n",
       "  'loss_variance': 0.010567632850241548,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.3052680492401123},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.47161102294921875},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.4109477996826172},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.0026128292083740234},\n",
       " {'loss': 0.33333333333333337,\n",
       "  'loss_variance': 0.009661835748792272,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.037741899490356445},\n",
       " {'loss': 0.75,\n",
       "  'loss_variance': 0.008152173913043478,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.0016520023345947266},\n",
       " {'loss': 0.08333333333333337,\n",
       "  'loss_variance': 0.0033212560386473443,\n",
       "  'status': 'ok',\n",
       "  'duration': 2.389080047607422},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.13408780097961426},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.01604294776916504},\n",
       " {'loss': 0.08333333333333337,\n",
       "  'loss_variance': 0.0033212560386473443,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.001634836196899414},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.011774301528930664},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.012379169464111328},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.03499007225036621},\n",
       " {'loss': 0.08333333333333337,\n",
       "  'loss_variance': 0.0033212560386473443,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.20871806144714355},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.5945048332214355},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 1.0521888732910156},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.03285074234008789},\n",
       " {'loss': 0.33333333333333337,\n",
       "  'loss_variance': 0.009661835748792272,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.010481834411621094},\n",
       " {'loss': 0.75,\n",
       "  'loss_variance': 0.008152173913043478,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.0017118453979492188},\n",
       " {'loss': 0.6666666666666667,\n",
       "  'loss_variance': 0.00966183574879227,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.06498503684997559},\n",
       " {'loss': 0.125,\n",
       "  'loss_variance': 0.004755434782608696,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.028120040893554688},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 1.093493938446045},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.7363510131835938},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 1.5166661739349365},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 1.0138170719146729},\n",
       " {'loss': 0.16666666666666663,\n",
       "  'loss_variance': 0.006038647342995168,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.0025238990783691406},\n",
       " {'loss': 0.75,\n",
       "  'loss_variance': 0.008152173913043478,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.0016891956329345703},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 1.0062670707702637},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.6933338642120361},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.045623064041137695},\n",
       " {'loss': 0.7083333333333333,\n",
       "  'loss_variance': 0.008982487922705316,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.0060999393463134766},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.009913206100463867},\n",
       " {'loss': 0.125,\n",
       "  'loss_variance': 0.004755434782608696,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.25100088119506836},\n",
       " {'loss': 0.08333333333333337,\n",
       "  'loss_variance': 0.0033212560386473443,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.007483005523681641},\n",
       " {'loss': 0.08333333333333337,\n",
       "  'loss_variance': 0.0033212560386473443,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.0031871795654296875},\n",
       " {'loss': 0.08333333333333337,\n",
       "  'loss_variance': 0.0033212560386473443,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.0066547393798828125},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.03617501258850098},\n",
       " {'loss': 0.75,\n",
       "  'loss_variance': 0.008152173913043478,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.004332780838012695},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.0069048404693603516},\n",
       " {'loss': 0.75,\n",
       "  'loss_variance': 0.008152173913043478,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.01612710952758789},\n",
       " {'loss': 0.08333333333333337,\n",
       "  'loss_variance': 0.0033212560386473443,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.0019378662109375},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.001451730728149414},\n",
       " {'loss': 0.33333333333333337,\n",
       "  'loss_variance': 0.009661835748792272,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.008466958999633789},\n",
       " {'loss': 0.08333333333333337,\n",
       "  'loss_variance': 0.0033212560386473443,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.08735179901123047},\n",
       " {'loss': 0.75,\n",
       "  'loss_variance': 0.008152173913043478,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.009508132934570312},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.09303617477416992},\n",
       " {'loss': 0.08333333333333337,\n",
       "  'loss_variance': 0.0033212560386473443,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.42041921615600586},\n",
       " {'loss': 0.75,\n",
       "  'loss_variance': 0.008152173913043478,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.03948211669921875},\n",
       " {'loss': 0.08333333333333337,\n",
       "  'loss_variance': 0.0033212560386473443,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.0016100406646728516},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.8639969825744629},\n",
       " {'loss': 0.75,\n",
       "  'loss_variance': 0.008152173913043478,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.0019059181213378906},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 1.371708869934082},\n",
       " {'loss': 0.75,\n",
       "  'loss_variance': 0.008152173913043478,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.0024819374084472656},\n",
       " {'loss': 0.75,\n",
       "  'loss_variance': 0.008152173913043478,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.03395700454711914},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.04526376724243164},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.11640191078186035},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.5127079486846924},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.010309934616088867},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.2488241195678711},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.3442420959472656},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.028049230575561523},\n",
       " {'loss': 0.08333333333333337,\n",
       "  'loss_variance': 0.0033212560386473443,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.031881093978881836},\n",
       " {'loss': 0.08333333333333337,\n",
       "  'loss_variance': 0.0033212560386473443,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.0482327938079834},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.021914958953857422},\n",
       " {'loss': 0.08333333333333337,\n",
       "  'loss_variance': 0.0033212560386473443,\n",
       "  'status': 'ok',\n",
       "  'duration': 1.190140962600708},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.04373502731323242},\n",
       " {'loss': 0.75,\n",
       "  'loss_variance': 0.008152173913043478,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.8985629081726074},\n",
       " {'loss': 0.08333333333333337,\n",
       "  'loss_variance': 0.0033212560386473443,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.019957304000854492},\n",
       " {'loss': 0.125,\n",
       "  'loss_variance': 0.004755434782608696,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.0028510093688964844},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.0016937255859375},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.6608822345733643},\n",
       " {'loss': 0.08333333333333337,\n",
       "  'loss_variance': 0.0033212560386473443,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.001990795135498047},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.6420750617980957},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 1.8026618957519531},\n",
       " {'loss': 0.08333333333333337,\n",
       "  'loss_variance': 0.0033212560386473443,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.48387765884399414},\n",
       " {'loss': 0.08333333333333337,\n",
       "  'loss_variance': 0.0033212560386473443,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.07634711265563965},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 1.94527006149292},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.9262371063232422},\n",
       " {'loss': 0.08333333333333337,\n",
       "  'loss_variance': 0.0033212560386473443,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.02380228042602539},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.01880788803100586},\n",
       " {'loss': 0.08333333333333337,\n",
       "  'loss_variance': 0.0033212560386473443,\n",
       "  'status': 'ok',\n",
       "  'duration': 1.8366436958312988},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.04493093490600586},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.0020689964294433594},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.0014309883117675781},\n",
       " {'loss': 0.41666666666666663,\n",
       "  'loss_variance': 0.010567632850241546,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.0033049583435058594},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.7916221618652344},\n",
       " {'loss': 0.125,\n",
       "  'loss_variance': 0.004755434782608696,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.6630058288574219},\n",
       " {'loss': 0.04166666666666663,\n",
       "  'loss_variance': 0.0017361111111111097,\n",
       "  'status': 'ok',\n",
       "  'duration': 0.6053130626678467}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estim.trials.results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c4a7925",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<hyperopt.pyll.base.Apply at 0x7fe9b14d62b0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "estim.spac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cb34fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
